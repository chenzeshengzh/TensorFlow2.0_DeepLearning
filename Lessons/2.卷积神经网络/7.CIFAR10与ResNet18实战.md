##### 深度残差网络实战

+ 数据集：CIFAR10 图片分类问题

+ ResNet模型类

  ```python
  import tensorflow as tf
  from tensorflow.keras import Sequential, layers
  
  
  class BasicBlock(layers.Layer):
      def __init__(self, filter_num, strides=1):
          super(BasicBlock, self).__init__()
          self.conv1 = layers.Conv2D(filter_num, kernel_size=3, strides=strides, padding='same')
          self.bn1 = layers.BatchNormalization()
          self.relu = layers.ReLU()
          self.conv2 = layers.Conv2D(filter_num, kernel_size=3, strides=1, padding='same')
          self.bn2 = layers.BatchNormalization()
          if strides != 1:
              self.downsample = Sequential()
              self.downsample.add(layers.Conv2D(filter_num, kernel_size=1, strides=strides, padding='same'))
          else:
              self.downsample = lambda x: x
  
      def call(self, inputs, training=None):
          out = self.conv1(inputs)
          out = self.bn1(out)
          out = self.relu(out)
          out = self.conv2(out)
          out = self.bn2(out)
          identity = self.downsample(inputs)
          output = layers.add([out, identity])
          output = self.relu(output)
          return output
  
  
  class ResNet(tf.keras.Model):
      def __init__(self, layer_dims, num_classes=10):
          super(ResNet, self).__init__()
          self.stem = Sequential([
              layers.Conv2D(64, kernel_size=3, strides=1),
              layers.BatchNormalization(),
              layers.ReLU(),
              layers.MaxPool2D(pool_size=2, strides=2, padding='same')
          ])
          self.layer1 = self.build_resblock(64, layer_dims[0])
          self.layer2 = self.build_resblock(128, layer_dims[1], 2)
          self.layer3 = self.build_resblock(256, layer_dims[2], 2)
          self.layer4 = self.build_resblock(512, layer_dims[3], 2)
          self.avgpool = layers.GlobalAveragePooling2D()
          self.fc = layers.Dense(num_classes)
  
      def call(self, inputs, training=None):
          x = self.stem(inputs)
          x = self.layer1(x)
          x = self.layer2(x)
          x = self.layer3(x)
          x = self.layer4(x)
          x = self.avgpool(x)
          x = self.fc(x)
          return x
  
      def build_resblock(self, filter_num, blocks, strides=1):
          res_blocks = Sequential()
          res_blocks.add(BasicBlock(filter_num, strides))
          for _ in range(1, blocks):
              res_blocks.add(BasicBlock(filter_num, strides=1))
          return res_blocks
  
  
  def resnet18():
      return ResNet([2, 2, 2, 2])
  
  
  def resnet34():
      return ResNet([3, 4, 6, 3])
  ```

  ---

+ Train-Test测试

  ```python
  import os
  import sys
  
  import tensorflow as tf
  from tensorflow.keras import datasets, optimizers, losses
  from resnet import resnet18
  
  os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
  os.environ["CUDA_VISIBLE_DEVICES"] = ""
  
  
  # gpu = tf.config.experimental.list_physical_devices('GPU')
  # assert len(gpu) > 0
  # tf.config.experimental.set_memory_growth(gpu[0], True)
  
  
  def preprocess(x, y):
      x = 2 * tf.cast(x, dtype=tf.float32) / 255. - 1
      y = tf.cast(y, dtype=tf.int32)
      return x, y
  
  
  (x, y), (x_test, y_test) = datasets.cifar10.load_data()
  y = tf.squeeze(y, axis=1)
  y_test = tf.squeeze(y_test, axis=1)
  train_db = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(1000).map(preprocess).batch(128)
  test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).map(preprocess).batch(128)
  
  
  def main():
      model = resnet18()
      model.build(input_shape=(128, 32, 32, 3))
      model.summary()
      optimizer = optimizers.Adam(lr=1e-4)
      for epoch in range(20):
          for step, (x, y) in enumerate(train_db):
              with tf.GradientTape() as tape:
                  logits = model(x)
                  y_onehot = tf.one_hot(y, depth=10)
                  loss = tf.reduce_mean(losses.categorical_crossentropy(y_onehot, logits, from_logits=True))
              grads = tape.gradient(loss, model.trainable_variables)
              optimizer.apply_gradients(zip(grads, model.trainable_variables))
          print(f'Epoch:{epoch}, Loss:{loss.numpy()}')
  
          total = 0
          correct = 0
          for x, y in test_db:
              logits = model(x)
              preds = tf.cast(tf.argmax(logits, axis=1), dtype=tf.int32)
              correct += tf.reduce_sum(tf.cast(tf.equal(preds, y), dtype=tf.int32))
              total += y.shape[0]
          acc = correct / total
          print(f'Epoch:{epoch}, Acc:{acc}')
  
  
  if __name__ == '__main__':
      main()
  ```

  