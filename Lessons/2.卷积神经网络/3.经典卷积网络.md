##### 经典卷积网络

+ AlexNet

  > 神经网络层数达到8层

  > 引入ReLU激活函数，摒弃了Sigmoid激活函数，有效避免了梯度弥散现象

  > 引入Dropout机制，提高了模型的泛化能力。

+ VGG

  > 神经网络层数达到19层

  > 卷积核采用$3 \times 3$，参数量更少，计算代价低

  > 池化核采用$2 \times 2$，补偿为$2$，长宽2倍数减小

+ GoogleNet

  > 采用$1 \times 1$卷积核优化通道，参数量更小

  > 神经网络层数达到22层

  > 模块化设计，推出堆叠Inception模块，形成了复杂网络结构

