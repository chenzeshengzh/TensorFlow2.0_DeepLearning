##### 过拟合问题实战

+ 问题

  > 利用月牙形状的2分类数据集，通过网络层数、Dropout、正则化等三个方面对比其对过拟合的影响。

+ 代码

  ```python
  import os
  
  import tensorflow as tf
  from matplotlib import pyplot as plt
  from sklearn.datasets import make_moons
  from sklearn.model_selection import train_test_split
  from tensorflow.keras import layers, Sequential, regularizers
  
  os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
  gpu = tf.config.experimental.list_physical_devices('GPU')
  assert len(gpu) > 0
  tf.config.experimental.set_memory_growth(gpu[0], True)
  
  x, y = make_moons(2000, noise=0.25, random_state=7)
  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=7)
  res = []
  
  
  def make_plot(x, y, name):
      plt.figure()
      axes = plt.gca()
      axes.set(xlabel='$x_1$', ylabel='$x_2$')
      plt.scatter(x[:, 0], x[:, 1], c=y.ravel(), s=40, marker='o')
      plt.title(name)
      plt.show()
  
  
  def train(model, info):
      model.add(layers.Dense(1, activation='sigmoid'))
      model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
      history = model.fit(x_train, y_train, epochs=100, verbose=1)
      preds = model.predict(x_test)
      preds = [0 if preds[i] <= 0.5 else 1 for i in range(preds.shape[0])]
      acc = tf.reduce_sum(tf.cast(tf.equal(y_test, preds), dtype=tf.int32)) / y_test.shape[0]
      info += f'准确率:{acc.numpy()}'
      res.append(info)
      print(info)
  
  
  def inf_layers():
      res.append('=' * 10 + '隐藏层数影响' + '=' * 10)
      for n in range(5):
          model = Sequential()
          model.add(layers.Dense(8, input_dim=2, activation='relu'))
          for _ in range(n):
              model.add(layers.Dense(32, activation='relu'))
          info = f'隐藏层数:{n + 1},'
          train(model, info)
  
  
  def inf_dropout():
      res.append('=' * 10 + 'dropout影响' + '=' * 10)
  
      model = Sequential()
      model.add(layers.Dense(8, input_dim=2, activation='relu'))
      for _ in range(5):
          model.add(layers.Dense(32, activation='relu'))
      info = f'无Dropout,'
      train(model, info)
  
      model = Sequential()
      model.add(layers.Dense(8, input_dim=2, activation='relu'))
      for _ in range(5):
          model.add(layers.Dense(32, activation='relu'))
          model.add(layers.Dropout(rate=0.5))
      info = f'有Dropout,'
      train(model, info)
  
  
  def inf_reg():
      res.append('=' * 10 + '正则化影响' + '=' * 10)
  
      model = Sequential()
      model.add(layers.Dense(8, input_dim=2, activation='relu'))
      for _ in range(5):
          model.add(layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)))
      info = f'采取L2正则化,'
      train(model, info)
  
  
  def main():
      make_plot(x, y, 'dataset')
      # 隐藏层数影响
      inf_layers()
      # dropout影响
      inf_dropout()
      # 正则化影响
      inf_reg()
  
      for item in res:
          print(item)
  
  
  if __name__ == '__main__':
      main()
  ```

  