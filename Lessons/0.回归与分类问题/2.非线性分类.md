##### 问题

> 在没有引入交叉熵概念的情况下，尝试继续使用均方损失对MNIST手写数据集搭建分类网络，该数据集包含0～9共计10个手写数字图片，以单通道灰度图形式存在，数据标签需要转化为one-hot形式。

---

##### 推导

> 拟搭建3层神经网络，并引入非线性操作$relu$函数，以下为网络架构：
>
> + 输入层：
>   $$
>   x\in R^{784}
>   $$
>
> + 隐藏层I：
>   $$
>   h_1 = {\operatorname{ReLU}}(W_1x+b_1)\in R^{256}\tag{1}
>   $$
>
> + 隐藏层II：
>   $$
>   h_2 = {\operatorname{ReLU}}(W_2h_1+b_2)\in R^{128}\tag{2}
>   $$
>
> + 输出层：
>   $$
>   o = (W_3h_2+b_3)\in R^{10}\tag{3}
>   $$
>
> 对$n$个样本，取均方差损失函数如下：
> $$
> L(o, y)=\frac{1}{n}\sum_{i=1}^n\sum_{j=1}^{10}(o_j^{(i)}-y_j^{(i)})\tag{4}
> $$
> 因此，待计算的网络参数转化为以下最优化问题：
> $$
> W^{\*}, b^{\*}=\underset{w, b}{\operatorname{arg\,min}}L(o, y)\tag{5}
> $$
> 最后，利用梯度下降算法更新如上参数$\theta=(W, b)$即可：
> $$
> \theta'=\theta-\eta\cdot\frac{\partial L}{\partial \theta}\tag{6}
> $$

---

##### 代码

```python
import os

import matplotlib
import tensorflow as tf
from matplotlib import pyplot as plt
from tensorflow.keras import layers, Sequential, losses, datasets, optimizers

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
matplotlib.rcParams['font.size'] = 18
matplotlib.rcParams['figure.titlesize'] = 18
matplotlib.rcParams['figure.figsize'] = [9, 7]
matplotlib.rcParams['font.family'] = ['STKaiti']
matplotlib.rcParams['axes.unicode_minus'] = False
gpu = tf.config.experimental.list_physical_devices('GPU')
assert len(gpu) > 0, 'NO GPU'
tf.config.experimental.set_memory_growth(gpu[0], True)


def main():
    loss_with_epochs = []
    batch_size = 512
    epochs = 30

    # get mnist dataset
    (x, y), (x_test, y_test) = datasets.mnist.load_data()
    x = 2 * tf.convert_to_tensor(x, dtype=tf.float32) / 255. - 1
    y = tf.convert_to_tensor(y, dtype=tf.int32)
    y = tf.one_hot(y, depth=10)
    train_db = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(1000).batch(batch_size)

    # build model
    model = Sequential([
        layers.Dense(256, activation='relu'),
        layers.Dense(128, activation='relu'),
        layers.Dense(10)
    ])
    optimizer = optimizers.Adam(lr=1e-3)

    # start training
    for epoch in range(epochs):
        for step, (x, y) in enumerate(train_db):
            with tf.GradientTape() as tape:
                x = tf.reshape(x, (-1, 28 * 28))
                out = model(x)
                loss = tf.reduce_mean(losses.mse(out, y), axis=0)
            grads = tape.gradient(loss, model.trainable_variables)
            optimizer.apply_gradients(zip(grads, model.trainable_variables))
            if step % 100 == 0:
                print(epoch, step, 'loss:', float(loss))
        loss_with_epochs.append(loss.numpy())

    # test
    x = 2 * tf.convert_to_tensor(x_test, dtype=tf.float32) / 255. - 1
    y = tf.convert_to_tensor(y_test, dtype=tf.int32)
    y = tf.one_hot(y, depth=10)
    out = model(tf.reshape(x, (-1, 28 * 28)))
    correct = tf.reduce_sum(tf.cast(tf.equal(tf.argmax(y, axis=1), tf.argmax(out, axis=1)), dtype=tf.int32))
    print('acc:', correct.numpy() / y_test.shape[0])

    # plot loss along epochs
    plt.figure()
    plt.plot(range(len(loss_with_epochs)), loss_with_epochs, label='训练误差')
    plt.plot(range(len(loss_with_epochs)), loss_with_epochs, 's')
    plt.legend()
    plt.title('MSE - Epochs')
    plt.xlabel('Epoch')
    plt.ylabel('MSE')
    plt.show()


if __name__ == '__main__':
    main()

```

---

##### 备注

> + 采用三层全连接网络进行手写数字训练，最终在测试集上取得95%以上正确率。
> + 本节采用均方指标作为损失函数，在多分类问题中，更通用的是交叉熵损失函数，在后文中进行介绍。
> + TensorFlow2.0 采用GradientTape自动梯度进行计算，推荐使用，接口清晰明了。